{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "829a4822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria liberada.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')\n",
    "gc.collect()\n",
    "print(\"Memoria liberada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Encontrados 150 archivos de imagen y 150 archivos de label.\n",
      ">> Emparejados 150 pares imagen-label.\n",
      "ℹProcesando todos los 150 volúmenes disponibles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexando volúmenes: 100%|██████████| 150/150 [00:01<00:00, 89.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indexación completada. 150 volúmenes listos para su procesamiento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Indexación de Todos los Volúmenes para Preprocesamiento\n",
    "# Indexa todos los pares imagen-label disponibles en TrainBatch1.\n",
    "# MODIFICADA: Limita el procesamiento a 20 volúmenes para ahorrar espacio.\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "\n",
    "# === 1. Configuración de rutas (relativas y solo TrainBatch1) ===\n",
    "DATA_PATHS = {\n",
    "    \"images_batch1\": r\"./TrainBatch1/imagesTr\",\n",
    "    \"labels_batch1\": r\"./TrainBatch1/labelsTr\",\n",
    "    # \"images_batch2\": r\"./TrainBatch2/imagesTr\",  # Comentado: no está disponible\n",
    "    # \"labels_batch2\": r\"./TrainBatch2/labelsTr\"   # Comentado: no está disponible\n",
    "}\n",
    "\n",
    "# === 2. Validación de rutas ===\n",
    "for key in [\"images_batch1\", \"labels_batch1\"]:\n",
    "    path = DATA_PATHS[key]\n",
    "    assert os.path.exists(path), f\"Ruta no encontrada: {path}\"\n",
    "\n",
    "# === 3. Conteo y emparejamiento de archivos ===\n",
    "images_path = DATA_PATHS[\"images_batch1\"]\n",
    "labels_path = DATA_PATHS[\"labels_batch1\"]\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(images_path) if f.endswith(\".nii.gz\")])\n",
    "label_files = sorted([f for f in os.listdir(labels_path) if f.endswith(\".nii.gz\")])\n",
    "\n",
    "print(f\">> Encontrados {len(image_files)} archivos de imagen y {len(label_files)} archivos de label.\")\n",
    "\n",
    "# Construir lista de pares (img_path, lbl_path)\n",
    "all_pairs = []\n",
    "for img_file in image_files:\n",
    "    base_id = img_file.replace(\"_0000.nii.gz\", \"\")\n",
    "    # Buscar el label correspondiente\n",
    "    matching_labels = [lbl for lbl in label_files if lbl.startswith(base_id)]\n",
    "    if matching_labels:\n",
    "        lbl_file = matching_labels[0]\n",
    "        all_pairs.append((\n",
    "            os.path.join(images_path, img_file),\n",
    "            os.path.join(labels_path, lbl_file)\n",
    "        ))\n",
    "    else:\n",
    "        print(f\"Advertencia: No se encontró label para {img_file}\")\n",
    "\n",
    "print(f\">> Emparejados {len(all_pairs)} pares imagen-label.\")\n",
    "\n",
    "# === 4. LIMITAR A 20 VOLÚMENES PARA AHORRAR ESPACIO ===\n",
    "MAX_VOLUMES = 150\n",
    "if len(all_pairs) > MAX_VOLUMES:\n",
    "    print(f\"Limitando el procesamiento a {MAX_VOLUMES} volúmenes (de {len(all_pairs)} disponibles) para ahorrar espacio.\")\n",
    "    all_pairs = all_pairs[:MAX_VOLUMES]\n",
    "else:\n",
    "    print(f\"ℹProcesando todos los {len(all_pairs)} volúmenes disponibles.\")\n",
    "\n",
    "# === 5. Indexación: cargar metadatos de los volúmenes seleccionados ===\n",
    "# Este paso es rápido porque solo carga el header, no los datos volumétricos.\n",
    "loaded_data = {}\n",
    "for img_path, lbl_path in tqdm(all_pairs, desc=\"Indexando volúmenes\"):\n",
    "    img_obj = nib.load(img_path, mmap=True)\n",
    "    vol_id = os.path.basename(img_path).replace(\"_0000.nii.gz\", \"\")\n",
    "    \n",
    "    loaded_data[vol_id] = {\n",
    "        \"img_path\": img_path,\n",
    "        \"lbl_path\": lbl_path,\n",
    "        \"affine\": img_obj.affine,\n",
    "        \"header\": img_obj.header.copy(),\n",
    "        \"zooms\": tuple(img_obj.header.get_zooms()[:3])\n",
    "    }\n",
    "    img_obj.uncache()  # Libera la memoria\n",
    "\n",
    "print(f\"\\nIndexación completada. {len(loaded_data)} volúmenes listos para su procesamiento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Definición de Técnicas de Preprocesamiento\n",
    "# Versión flexible que, con sus parámetros por defecto, replica el flujo de auditoría.\n",
    "# CORREGIDA: sigma=0.8 para alinearse con la metodología validada.\n",
    "# MODIFICADA: Normalización con rango fijo + reversión para pipeline masivo.\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# Helper: ensure ROI and volume have the same shape\n",
    "# -------------------------\n",
    "def match_shape(vol, roi):\n",
    "    \"\"\"Ajusta ROI para que coincida con la forma del volumen (crop/pad centrado).\"\"\"\n",
    "    if roi is None:\n",
    "        return None\n",
    "    roi = roi.astype(bool, copy=False)\n",
    "    Z, Y, X = vol.shape\n",
    "    rz, ry, rx = roi.shape\n",
    "\n",
    "    # Crop ROI si es más grande\n",
    "    if rz > Z or ry > Y or rx > X:\n",
    "        z0 = max((rz - Z) // 2, 0)\n",
    "        y0 = max((ry - Y) // 2, 0)\n",
    "        x0 = max((rx - X) // 2, 0)\n",
    "        roi = roi[z0:z0+Z, y0:y0+Y, x0:x0+X]\n",
    "\n",
    "    # Pad ROI si es más pequeña\n",
    "    diffZ = Z - roi.shape[0]\n",
    "    diffY = Y - roi.shape[1]\n",
    "    diffX = X - roi.shape[2]\n",
    "    if diffZ > 0 or diffY > 0 or diffX > 0:\n",
    "        pad_width = (\n",
    "            (0, max(diffZ, 0)),\n",
    "            (0, max(diffY, 0)),\n",
    "            (0, max(diffX, 0)),\n",
    "        )\n",
    "        roi = np.pad(roi, pad_width, mode=\"constant\", constant_values=False)\n",
    "\n",
    "    return roi[:Z, :Y, :X]\n",
    "\n",
    "# -------------------------\n",
    "# 1) HU Clipping\n",
    "# -------------------------\n",
    "def apply_hu_clipping(volume, hu_min=-1024, hu_max=600):\n",
    "    \"\"\"\n",
    "    Aplica clipping en HU al rango [hu_min, hu_max].\n",
    "    \"\"\"\n",
    "    return np.clip(volume.astype(np.float32, copy=False), hu_min, hu_max)\n",
    "\n",
    "# -------------------------\n",
    "# 2) Gaussian Smoothing\n",
    "# -------------------------\n",
    "def apply_gaussian_smoothing(volume, sigma=0.8):\n",
    "    \"\"\"\n",
    "    Aplica suavizado gaussiano isotrópico.\n",
    "    - sigma=0.8: un valor ligeramente más conservador que 1.0 para preservar vías finas.\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    return gaussian_filter(volume.astype(np.float32), sigma=sigma)\n",
    "\n",
    "# -------------------------\n",
    "# 3) Normalización Min-Max con Rango Fijo + Reversión\n",
    "# -------------------------\n",
    "# Diccionario global para guardar los parámetros de normalización por caso.\n",
    "_NORMALIZATION_PARAMS = {}\n",
    "\n",
    "def apply_minmax_normalization(volume, case_id=\"default\"):\n",
    "    \"\"\"\n",
    "    Aplica normalización Min-Max al rango [0, 1] usando el rango fijo [-1024, 600].\n",
    "    Guarda los parámetros para su reversión.\n",
    "    \"\"\"\n",
    "    vol_float = volume.astype(np.float32, copy=False)\n",
    "    hu_min, hu_max = -1024.0, 600.0  # Rango fijo\n",
    "    normalized = (vol_float - hu_min) / (hu_max - hu_min)\n",
    "    # Guardar los parámetros (siempre los mismos, pero por consistencia)\n",
    "    _NORMALIZATION_PARAMS[case_id] = (hu_min, hu_max)\n",
    "    return normalized\n",
    "\n",
    "def revert_normalization(normalized_volume, case_id=\"default\"):\n",
    "    \"\"\"\n",
    "    Revierte la normalización Min-Max usando el rango fijo [-1024, 600].\n",
    "    \"\"\"\n",
    "    hu_min, hu_max = -1024.0, 600.0  # Rango fijo\n",
    "    return normalized_volume * (hu_max - hu_min) + hu_min\n",
    "\n",
    "# -------------------------\n",
    "# 4) Padding (symmetrical, multiples of 32)\n",
    "# -------------------------\n",
    "def apply_padding_32(volume, pad_value=-1024):\n",
    "    \"\"\"\n",
    "    Aplica padding simétrico para ajustar a múltiplos de 32.\n",
    "    Usa el valor de aire exterior (-1024) como constante de relleno.\n",
    "    \"\"\"\n",
    "    shape = volume.shape\n",
    "    pad_width = []\n",
    "    for dim in shape:\n",
    "        remainder = dim % 32\n",
    "        if remainder == 0:\n",
    "            pad_before, pad_after = 0, 0\n",
    "        else:\n",
    "            pad_total = 32 - remainder\n",
    "            pad_before = pad_total // 2\n",
    "            pad_after = pad_total - pad_before\n",
    "        pad_width.append((pad_before, pad_after))\n",
    "    \n",
    "    padded = np.pad(volume, pad_width, mode='constant', constant_values=pad_value)\n",
    "    return padded.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinación seleccionada: Clipped_Smoothed_Normalized_Padded\n",
      "   Técnicas: ['Clipped', 'Smoothed', 'Normalized', 'Padded']\n",
      "\n",
      "Las combinaciones se guardarán en: c:\\Users\\pipea\\OneDrive\\Escritorio\\PIB\\PreProce_All\n",
      "Carpeta creada: Clipped_Smoothed_Normalized_Padded\n",
      "\n",
      "Iniciando el procesamiento de 150 volúmenes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Clipped_Smoothed_Normalized_Padded: 100%|██████████| 150/150 [1:05:30<00:00, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESUMEN DE LA GENERACIÓN: Clipped_Smoothed_Normalized_Padded\n",
      "======================================================================\n",
      "Total de volúmenes procesados: 150\n",
      "Total de volúmenes saltados (ya existentes): 0\n",
      "Total de archivos generados: 150\n",
      "Volúmenes fallidos: 0\n",
      "\n",
      "Procesamiento completado para: Clipped_Smoothed_Normalized_Padded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Generación de UNA Combinación Específica para Todos los Volúmenes\n",
    "# Aplica UNA combinación de preprocesamiento a todos los volúmenes indexados.\n",
    "# CORREGIDA: Orden lógico + Verificación de existencia + case_id en normalización.\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# === 1. SELECCIONAR LA COMBINACIÓN ESPECÍFICA ===\n",
    "# Opciones disponibles (elige UNA):\n",
    "COMBINACION_SELECCIONADA = \"Clipped_Smoothed_Normalized_Padded\"  \n",
    "\n",
    "# Mapeo de nombres a configuraciones\n",
    "combinacion_config = {\n",
    "    \"Clipped\": [0],\n",
    "    \"Smoothed\": [1], \n",
    "    \"Normalized\": [2],\n",
    "    \"Padded\": [3],\n",
    "    \"Clipped_Smoothed\": [0, 1],\n",
    "    \"Clipped_Normalized\": [0, 2],\n",
    "    \"Clipped_Padded\": [0, 3],\n",
    "    \"Smoothed_Normalized\": [1, 2],\n",
    "    \"Smoothed_Padded\": [1, 3],\n",
    "    \"Normalized_Padded\": [2, 3],\n",
    "    \"Clipped_Smoothed_Normalized\": [0, 1, 2],\n",
    "    \"Clipped_Smoothed_Padded\": [0, 1, 3],\n",
    "    \"Clipped_Normalized_Padded\": [0, 2, 3],\n",
    "    \"Smoothed_Normalized_Padded\": [1, 2, 3],\n",
    "    \"Clipped_Smoothed_Normalized_Padded\": [0, 1, 2, 3]\n",
    "}\n",
    "\n",
    "if COMBINACION_SELECCIONADA not in combinacion_config:\n",
    "    raise ValueError(f\"❌ Combinación '{COMBINACION_SELECCIONADA}' no válida.\\n\"\n",
    "                    f\"Opciones disponibles: {list(combinacion_config.keys())}\")\n",
    "\n",
    "combo_subset = combinacion_config[COMBINACION_SELECCIONADA]\n",
    "print(f\"Combinación seleccionada: {COMBINACION_SELECCIONADA}\")\n",
    "print(f\"   Técnicas: {[['Clipped','Smoothed','Normalized','Padded'][i] for i in combo_subset]}\")\n",
    "\n",
    "# === 2. Configuración de la ruta base de salida ===\n",
    "OUTPUT_BASE_DIR = r\"./PreProce_All\"\n",
    "os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)\n",
    "print(f\"\\nLas combinaciones se guardarán en: {os.path.abspath(OUTPUT_BASE_DIR)}\")\n",
    "\n",
    "# === 3. Crear carpeta para la combinación seleccionada ===\n",
    "folder_name = COMBINACION_SELECCIONADA\n",
    "combo_output_dir = os.path.join(OUTPUT_BASE_DIR, folder_name)\n",
    "os.makedirs(combo_output_dir, exist_ok=True)\n",
    "print(f\"Carpeta creada: {folder_name}\")\n",
    "\n",
    "# === 4. Procesar cada volumen para la combinación seleccionada ===\n",
    "print(f\"\\nIniciando el procesamiento de {len(loaded_data)} volúmenes...\")\n",
    "\n",
    "total_saved = 0\n",
    "failed_volumes = []\n",
    "skipped_volumes = 0\n",
    "\n",
    "for vol_id, meta in tqdm(loaded_data.items(), desc=f\"Procesando {COMBINACION_SELECCIONADA}\"):\n",
    "    try:\n",
    "        output_filename = os.path.basename(meta[\"img_path\"])\n",
    "        vol_output_dir = os.path.join(combo_output_dir, vol_id)\n",
    "        output_path = os.path.join(vol_output_dir, output_filename)\n",
    "        \n",
    "        # Verificar si ya existe\n",
    "        if os.path.exists(output_path):\n",
    "            skipped_volumes += 1\n",
    "            continue\n",
    "        \n",
    "        # Cargar el volumen original\n",
    "        img_obj = nib.load(meta[\"img_path\"])\n",
    "        vol_orig = img_obj.get_fdata(dtype=np.float32)\n",
    "        affine, header = img_obj.affine, img_obj.header\n",
    "        \n",
    "        # Aplicar la combinación seleccionada\n",
    "        vol = vol_orig.copy()\n",
    "        \n",
    "        # Aplicar técnicas en orden lógico CORREGIDO:\n",
    "        # Clipping → Suavizado → Padding → Normalización\n",
    "        if 0 in combo_subset:  # Clipped\n",
    "            vol = apply_hu_clipping(vol)\n",
    "        if 1 in combo_subset:  # Smoothed\n",
    "            vol = apply_gaussian_smoothing(vol)\n",
    "        if 3 in combo_subset:  # Padded\n",
    "            vol = apply_padding_32(vol)  # Padding en escala HU original\n",
    "        if 2 in combo_subset:  # Normalized\n",
    "            vol = apply_minmax_normalization(vol, case_id=vol_id)  # ← ¡¡¡AÑADIDO case_id=vol_id!!!\n",
    "        \n",
    "        # Guardar el volumen preprocesado\n",
    "        os.makedirs(vol_output_dir, exist_ok=True)\n",
    "        output_nii = nib.Nifti1Image(vol, affine=affine, header=header)\n",
    "        nib.save(output_nii, output_path)\n",
    "        total_saved += 1\n",
    "        \n",
    "        img_obj.uncache()\n",
    "        del vol_orig, vol, output_nii\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError al procesar {vol_id}: {str(e)}\")\n",
    "        failed_volumes.append(vol_id)\n",
    "\n",
    "# === 5. Resumen final ===\n",
    "processed_volumes = len(loaded_data) - len(failed_volumes) - skipped_volumes\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"RESUMEN DE LA GENERACIÓN: {COMBINACION_SELECCIONADA}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total de volúmenes procesados: {processed_volumes}\")\n",
    "print(f\"Total de volúmenes saltados (ya existentes): {skipped_volumes}\")\n",
    "print(f\"Total de archivos generados: {total_saved}\")\n",
    "print(f\"Volúmenes fallidos: {len(failed_volumes)}\")\n",
    "\n",
    "if failed_volumes:\n",
    "    print(\"\\nVolúmenes fallidos:\")\n",
    "    for vol in failed_volumes:\n",
    "        print(f\" - {vol}\")\n",
    "\n",
    "if skipped_volumes > 0:\n",
    "    print(f\"\\nℹ{skipped_volumes} volúmenes ya existían y fueron saltados.\")\n",
    "\n",
    "print(f\"\\nProcesamiento completado para: {COMBINACION_SELECCIONADA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando vías aéreas para: Clipped_Smoothed_Normalized_Padded\n",
      "\n",
      "Ruta de combinación: ./PreProce_All\\Clipped_Smoothed_Normalized_Padded\n",
      "\n",
      "Procesando combinación: Clipped_Smoothed_Normalized_Padded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Volúmenes en Clipped_Smoothed_Normalized_Padded: 100%|██████████| 150/150 [2:10:30<00:00, 52.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESUMEN DE LA GENERACIÓN DE VÍAS AÉREAS: Clipped_Smoothed_Normalized_Padded\n",
      "======================================================================\n",
      "Total de máscaras generadas: 150\n",
      "Total de máscaras ya existentes: 0\n",
      "Total procesado (incluyendo existentes): 150\n",
      "Total de casos fallidos: 0\n",
      "\n",
      "Generación de vías aéreas completada para: Clipped_Smoothed_Normalized_Padded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Generación de Vías Aéreas para UNA Combinación Específica\n",
    "# USA LAS ROIS PREEXISTENTES DE ./rois_auto/ Y EL PIPELINE TUBULAR COMPLETO.\n",
    "# MODIFICADA: Procesa solo la combinación seleccionada + validación + reversión.\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from skimage.morphology import ball\n",
    "from scipy.ndimage import (\n",
    "    label as cc_label, \n",
    "    binary_dilation, \n",
    "    binary_closing\n",
    ")\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === SELECCIONAR LA MISMA COMBINACIÓN QUE EN CELL 3 ===\n",
    "COMBINACION_SELECCIONADA = \"Clipped_Smoothed_Normalized_Padded\"\n",
    "\n",
    "print(f\"Procesando vías aéreas para: {COMBINACION_SELECCIONADA}\")\n",
    "\n",
    "# === Función: Pipeline de Vías Aéreas (IDÉNTICO a Cell 4 TUBULAR) ===\n",
    "def generate_airways_tubular(vol_clip, final_roi):\n",
    "    \"\"\"Genera máscara de vías aéreas usando el pipeline TUBULAR exacto de Cell 4.\"\"\"    \n",
    "    roi_hu_values = vol_clip[final_roi > 0]\n",
    "    if roi_hu_values.size == 0:\n",
    "        return np.zeros_like(vol_clip, dtype=np.uint8)\n",
    "    \n",
    "    # --- Step 0: Umbrales adaptativos más estrictos ---\n",
    "    GROW_THR = np.percentile(roi_hu_values, 3)\n",
    "    AIR_THR_STRICT = min(-980, np.percentile(roi_hu_values, 0.5))\n",
    "\n",
    "    # --- Step 1-3: Segmentación inicial con BFS (sin tolerancia) ---\n",
    "    seeds = (vol_clip <= AIR_THR_STRICT) & (final_roi > 0)\n",
    "    Z, Y, X = vol_clip.shape\n",
    "    top = np.zeros_like(seeds, dtype=bool)\n",
    "    top[:int(Z * 0.5)] = True\n",
    "    trachea_cand = seeds & top\n",
    "    labeled_top, n_top = cc_label(trachea_cand)\n",
    "    if n_top > 0:\n",
    "        sizes_top = np.bincount(labeled_top.ravel())\n",
    "        sizes_top[0] = 0\n",
    "        trachea_label = np.argmax(sizes_top)\n",
    "        trachea = labeled_top == trachea_label\n",
    "    else:\n",
    "        trachea = np.zeros_like(seeds, dtype=bool)\n",
    "\n",
    "    airways_mask_bfs = np.zeros_like(seeds, dtype=np.uint8)\n",
    "    q = deque()\n",
    "    seed_pts = np.argwhere(trachea)\n",
    "    for s in seed_pts:\n",
    "        airways_mask_bfs[tuple(s)] = 1\n",
    "        q.append(tuple(s))\n",
    "\n",
    "    def neighbors6(z, y, x, shape):\n",
    "        for dz, dy, dx in [(1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)]:\n",
    "            nz, ny, nx = z + dz, y + dy, x + dx\n",
    "            if 0 <= nz < shape[0] and 0 <= ny < shape[1] and 0 <= nx < shape[2]:\n",
    "                yield nz, ny, nx\n",
    "\n",
    "    # BFS estricto\n",
    "    while q:\n",
    "        z, y, x = q.popleft()\n",
    "        for nz, ny, nx in neighbors6(z, y, x, airways_mask_bfs.shape):\n",
    "            if airways_mask_bfs[nz, ny, nx] == 0 and final_roi[nz, ny, nx] > 0:\n",
    "                neighbor_val = vol_clip[nz, ny, nx]\n",
    "                if neighbor_val <= GROW_THR:\n",
    "                    airways_mask_bfs[nz, ny, nx] = 1\n",
    "                    q.append((nz, ny, nx))\n",
    "\n",
    "    # Post-procesamiento inicial\n",
    "    airways_mask = airways_mask_bfs.astype(bool)\n",
    "    airways_mask = binary_dilation(airways_mask, iterations=1)\n",
    "    airways_mask = binary_closing(airways_mask, structure=ball(2))\n",
    "\n",
    "    # --- Step 4: Filtrado por forma tubular ---\n",
    "    labeled_mask, n_components = cc_label(airways_mask)\n",
    "    if n_components > 1:\n",
    "        component_sizes = np.bincount(labeled_mask.ravel())\n",
    "        component_sizes[0] = 0\n",
    "        main_component_id = np.argmax(component_sizes)\n",
    "        valid_mask = np.zeros_like(airways_mask, dtype=bool)\n",
    "        valid_mask[labeled_mask == main_component_id] = True  # Mantener componente principal\n",
    "        \n",
    "        for i in range(1, n_components + 1):\n",
    "            if i == main_component_id:\n",
    "                continue\n",
    "            comp_mask = labeled_mask == i\n",
    "            size = np.sum(comp_mask)\n",
    "            # Filtrar por tamaño\n",
    "            if size < 30 or size > 50000:\n",
    "                continue\n",
    "            \n",
    "            # Calcular bounding box para análisis de forma\n",
    "            coords = np.argwhere(comp_mask)\n",
    "            if len(coords) == 0:\n",
    "                continue\n",
    "            z_min, y_min, x_min = coords.min(axis=0)\n",
    "            z_max, y_max, x_max = coords.max(axis=0)\n",
    "            dz = max(1, z_max - z_min)\n",
    "            dy = max(1, y_max - y_min)\n",
    "            dx = max(1, x_max - x_min)\n",
    "            dimensions = np.sort([dz, dy, dx])\n",
    "            \n",
    "            # Criterio tubular: la dimensión más larga debe ser al menos 2x la más corta\n",
    "            if dimensions[2] >= 2 * dimensions[0]:\n",
    "                valid_mask[comp_mask] = True\n",
    "        \n",
    "        airways_mask = valid_mask\n",
    "\n",
    "    # --- Step 5: Extensión iterativa para vías finas ---\n",
    "    extended_mask = airways_mask.copy()\n",
    "    current_frontier = airways_mask.copy()\n",
    "    thresholds = [-890, -400, 0]\n",
    "    for current_thr in thresholds:\n",
    "        next_frontier = np.zeros_like(extended_mask)\n",
    "        dilated = binary_dilation(current_frontier, iterations=1)\n",
    "        frontier = dilated & (~extended_mask)\n",
    "        for z, y, x in np.argwhere(frontier):\n",
    "            if final_roi[z, y, x] > 0 and vol_clip[z, y, x] <= current_thr:\n",
    "                extended_mask[z, y, x] = 1\n",
    "                next_frontier[z, y, x] = 1\n",
    "        current_frontier = next_frontier\n",
    "        if not np.any(current_frontier):\n",
    "            break\n",
    "\n",
    "    # --- Step 6: Resultado final ---\n",
    "    return extended_mask.astype(np.uint8)\n",
    "\n",
    "# === Configuración de rutas ===\n",
    "INPUT_BASE_DIR = r\"./PreProce_All\"\n",
    "ROIS_AUTO_DIR = r\"./rois_auto\"  # Carpeta con ROIs pregeneradas\n",
    "\n",
    "# Verificar que la carpeta de ROIs existe\n",
    "if not os.path.exists(ROIS_AUTO_DIR):\n",
    "    raise FileNotFoundError(f\"Carpeta de ROIs no encontrada: {os.path.abspath(ROIS_AUTO_DIR)}\")\n",
    "\n",
    "# Verificar que la combinación seleccionada existe\n",
    "combo_path = os.path.join(INPUT_BASE_DIR, COMBINACION_SELECCIONADA)\n",
    "if not os.path.exists(combo_path):\n",
    "    raise FileNotFoundError(f\"Combinación '{COMBINACION_SELECCIONADA}' no encontrada en {INPUT_BASE_DIR}\")\n",
    "\n",
    "print(f\"\\nRuta de combinación: {combo_path}\")\n",
    "\n",
    "# === Procesar solo la combinación seleccionada ===\n",
    "total_processed = 0\n",
    "failed_cases = []\n",
    "skipped_existing = 0\n",
    "\n",
    "print(f\"\\nProcesando combinación: {COMBINACION_SELECCIONADA}\")\n",
    "\n",
    "# Recorrer cada carpeta de volumen dentro de la combinación seleccionada\n",
    "vol_folders = [d for d in os.listdir(combo_path) if os.path.isdir(os.path.join(combo_path, d))]\n",
    "for vol_id in tqdm(vol_folders, desc=f\"  Volúmenes en {COMBINACION_SELECCIONADA}\"):\n",
    "    vol_path = os.path.join(combo_path, vol_id)\n",
    "    \n",
    "    # Encontrar el archivo de volumen\n",
    "    nii_files = [f for f in os.listdir(vol_path) if f.endswith(\".nii.gz\")]\n",
    "    if not nii_files:\n",
    "        continue\n",
    "    vol_filename = nii_files[0]\n",
    "    vol_file_path = os.path.join(vol_path, vol_filename)\n",
    "    \n",
    "    # === VERIFICAR SI LA MÁSCARA DE VÍAS AÉREAS YA EXISTE ===\n",
    "    airways_filename = vol_filename.replace(\"_0000.nii.gz\", \"_airways.nii.gz\")\n",
    "    airways_path = os.path.join(vol_path, airways_filename)\n",
    "    \n",
    "    if os.path.exists(airways_path):\n",
    "        total_processed += 1\n",
    "        skipped_existing += 1\n",
    "        continue  # Saltar si ya existe\n",
    "    \n",
    "    try:\n",
    "        # Cargar el volumen preprocesado\n",
    "        img = nib.load(vol_file_path)\n",
    "        vol_preproc = img.get_fdata(dtype=np.float32)\n",
    "        affine = img.affine\n",
    "        \n",
    "        # === Cargar la ROI preexistente ===\n",
    "        roi_path = os.path.join(ROIS_AUTO_DIR, f\"{vol_id}.nii.gz\")\n",
    "        if not os.path.exists(roi_path):\n",
    "            error_msg = f\"ROI no encontrada para {vol_id}\"\n",
    "            failed_cases.append(f\"{COMBINACION_SELECCIONADA}/{vol_id}: {error_msg}\")\n",
    "            continue\n",
    "            \n",
    "        roi_img = nib.load(roi_path)\n",
    "        final_roi_original = roi_img.get_fdata().astype(np.uint8)\n",
    "        \n",
    "        # === Manejo del padding: ajustar la ROI si es necesario ===\n",
    "        if \"Padded\" in COMBINACION_SELECCIONADA:\n",
    "            from scipy.ndimage import zoom\n",
    "            vol_shape = vol_preproc.shape\n",
    "            roi_shape = final_roi_original.shape\n",
    "            \n",
    "            # Calcular factores de zoom\n",
    "            zoom_factors = [vol_shape[i] / roi_shape[i] for i in range(3)]\n",
    "            final_roi_for_vol = zoom(final_roi_original.astype(float), zoom_factors, order=0)\n",
    "            final_roi_for_vol = (final_roi_for_vol > 0.5).astype(np.uint8)\n",
    "            \n",
    "            if final_roi_for_vol.shape != vol_shape:\n",
    "                error_msg = f\"Formas no coinciden después del padding\"\n",
    "                failed_cases.append(f\"{COMBINACION_SELECCIONADA}/{vol_id}: {error_msg}\")\n",
    "                continue\n",
    "                \n",
    "            roi_for_segmentation = final_roi_for_vol\n",
    "            vol_for_segmentation = vol_preproc\n",
    "        else:\n",
    "            # Verificar que las formas coincidan\n",
    "            if vol_preproc.shape != final_roi_original.shape:\n",
    "                error_msg = f\"Formas no coinciden: vol={vol_preproc.shape}, roi={final_roi_original.shape}\"\n",
    "                failed_cases.append(f\"{COMBINACION_SELECCIONADA}/{vol_id}: {error_msg}\")\n",
    "                continue\n",
    "                \n",
    "            roi_for_segmentation = final_roi_original\n",
    "            vol_for_segmentation = vol_preproc\n",
    "        \n",
    "        # === ¡¡¡AÑADIR REVERSIÓN DE NORMALIZACIÓN!!! ===\n",
    "        if \"Normalized\" in COMBINACION_SELECCIONADA:\n",
    "            vol_for_segmentation = revert_normalization(vol_for_segmentation, case_id=vol_id)\n",
    "        \n",
    "        # === Generar vías aéreas usando el pipeline TUBULAR exacto ===\n",
    "        airways_mask = generate_airways_tubular(vol_for_segmentation, roi_for_segmentation)\n",
    "        \n",
    "        # Guardar la máscara en la misma carpeta del volumen\n",
    "        airways_nii = nib.Nifti1Image(airways_mask, affine=affine)\n",
    "        nib.save(airways_nii, airways_path)\n",
    "        \n",
    "        total_processed += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error de procesamiento: {str(e)}\"\n",
    "        failed_cases.append(f\"{COMBINACION_SELECCIONADA}/{vol_id}: {error_msg}\")\n",
    "\n",
    "# === Resumen final ===\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"RESUMEN DE LA GENERACIÓN DE VÍAS AÉREAS: {COMBINACION_SELECCIONADA}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total de máscaras generadas: {total_processed - skipped_existing}\")\n",
    "print(f\"Total de máscaras ya existentes: {skipped_existing}\")\n",
    "print(f\"Total procesado (incluyendo existentes): {total_processed}\")\n",
    "print(f\"Total de casos fallidos: {len(failed_cases)}\")\n",
    "\n",
    "if skipped_existing > 0:\n",
    "    print(f\"\\nℹ{skipped_existing} volúmenes ya tenían máscaras y fueron saltados.\")\n",
    "\n",
    "if failed_cases:\n",
    "    print(\"\\nCasos fallidos:\")\n",
    "    for err in failed_cases:\n",
    "        print(f\" - {err}\")\n",
    "\n",
    "print(f\"\\nGeneración de vías aéreas completada para: {COMBINACION_SELECCIONADA}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
