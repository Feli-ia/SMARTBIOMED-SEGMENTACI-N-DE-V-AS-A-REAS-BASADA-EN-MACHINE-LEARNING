{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb990f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria liberada.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')\n",
    "gc.collect()\n",
    "print(\"Memoria liberada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00bd8f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Configuration loaded.\n",
      "Batch1 imagesTr: 150 archivos\n",
      "Batch1 labelsTr: 150 archivos\n",
      "TOTAL archivos en la base: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing volumes from TrainBatch1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:00<00:00, 597.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Indexed 150 volumes from TrainBatch1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1 - ConfiguraciÃ³n inicial y carga de datos (Batch1 Only)\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "\n",
    "# Limitar hilos de BLAS/OpenMP (para evitar sobrecarga en CPU)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# -------------------------\n",
    "# Global parameters (HU Clipping alineado con roi.ipynb)\n",
    "# -------------------------\n",
    "HU_MIN, HU_MAX = -1024, 600\n",
    "\n",
    "# -------------------------\n",
    "# Database paths (SOLO TrainBatch1)\n",
    "# -------------------------\n",
    "# Se usan rutas absolutas como en tu entorno original de trabajo\n",
    "DATA_PATHS = {\n",
    "    \"images_batch1\": r\"./TrainBatch1/imagesTr\",\n",
    "    \"labels_batch1\": r\"./TrainBatch1/labelsTr\",\n",
    "    # \"images_batch2\": r\"./TrainBatch2/imagesTr\",  # Comentado: no estÃ¡ disponible\n",
    "    # \"labels_batch2\": r\"./TrainBatch2/labelsTr\"   # Comentado: no estÃ¡ disponible\n",
    "}\n",
    "\n",
    "# Validar solo las rutas existentes\n",
    "for key in [\"images_batch1\", \"labels_batch1\"]:\n",
    "    path = DATA_PATHS[key]\n",
    "    assert os.path.exists(path), f\"Path not found: {path}\"\n",
    "\n",
    "# -------------------------\n",
    "# Count files\n",
    "# -------------------------\n",
    "counts = {}\n",
    "for key in [\"images_batch1\", \"labels_batch1\"]:\n",
    "    path = DATA_PATHS[key]\n",
    "    files = [f for f in os.listdir(path) if f.endswith(\".nii.gz\")]\n",
    "    counts[key] = len(files)\n",
    "\n",
    "print(\">> Configuration loaded.\")\n",
    "print(f\"Batch1 imagesTr: {counts['images_batch1']} archivos\")\n",
    "print(f\"Batch1 labelsTr: {counts['labels_batch1']} archivos\")\n",
    "print(f\"TOTAL archivos en la base: {sum(counts.values())}\")\n",
    "\n",
    "# -------------------------\n",
    "# Build combined list of volumes and labels (SOLO Batch1)\n",
    "# -------------------------\n",
    "all_pairs = []\n",
    "# Solo procesar batch1\n",
    "batch = \"batch1\"\n",
    "images_path = DATA_PATHS[f\"images_{batch}\"]\n",
    "labels_path = DATA_PATHS[f\"labels_{batch}\"]\n",
    "image_files = [f for f in os.listdir(images_path) if f.endswith(\".nii.gz\")]\n",
    "for img_file in image_files:\n",
    "    base_id = img_file.replace(\"_0000.nii.gz\", \"\")\n",
    "    candidates = [f for f in os.listdir(labels_path) if base_id in f]\n",
    "    if candidates:\n",
    "        label_file = candidates[0]\n",
    "        all_pairs.append((os.path.join(images_path, img_file),\n",
    "                          os.path.join(labels_path, label_file)))\n",
    "assert len(all_pairs) > 0, \"No image-label pairs found in TrainBatch1.\"\n",
    "\n",
    "# -------------------------\n",
    "# Index all volumes (preserve original metadata)\n",
    "# -------------------------\n",
    "loaded_data = {}\n",
    "for img_path, lbl_path in tqdm(all_pairs, desc=\"Indexing volumes from TrainBatch1\"):\n",
    "    img_obj = nib.load(img_path, mmap=True)\n",
    "    vol_id = os.path.basename(img_path).replace(\"_0000.nii.gz\", \"\")\n",
    "    # âœ… Guardamos affine y header originales sin modificarlos\n",
    "    loaded_data[vol_id] = {\n",
    "        \"img_path\": img_path,\n",
    "        \"lbl_path\": lbl_path,\n",
    "        \"affine\": img_obj.affine,\n",
    "        \"header\": img_obj.header.copy(),\n",
    "        \"zooms\": tuple(img_obj.header.get_zooms()[:3])\n",
    "    }\n",
    "    img_obj.uncache()  # liberar mmap\n",
    "    del img_obj\n",
    "\n",
    "print(f\">> Indexed {len(loaded_data)} volumes from TrainBatch1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f2fdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Procesando 0 volÃºmenes con pipeline de roi.ipynb (bÃºsqueda multi-eje)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando ROIs: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ROIs generadas para todos los volÃºmenes. Pipeline fiel a Cell 2-3 (bÃºsqueda multi-eje).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "#   Procesamiento masivo â€” ALINEADO CON Cell 2-3 (bÃºsqueda multi-eje)\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import remove_small_objects, binary_closing, binary_dilation, ball\n",
    "from skimage.segmentation import clear_border\n",
    "from scipy.ndimage import label as cc_label, binary_fill_holes\n",
    "from collections import deque\n",
    "\n",
    "# --- Rutas ---\n",
    "OUTPUT_DIR = r\".\"  \n",
    "ROIS_SUBDIR = os.path.join(OUTPUT_DIR, \"rois_auto\")\n",
    "os.makedirs(ROIS_SUBDIR, exist_ok=True)\n",
    "\n",
    "# --- ParÃ¡metros (Â¡IGUALES que en roi.ipynb!) ---\n",
    "AIR_THR_STRICT_ROI = -950\n",
    "GROW_THR_ROI = -700\n",
    "MIN_SIZE_ROI = 50          # âœ… Alineado con Cell 2-3\n",
    "SMOOTH_RADIUS_ROI = 5      # âœ… Alineado con Cell 2-3\n",
    "HU_MIN, HU_MAX = -1024, 600\n",
    "\n",
    "# --- Verificar volÃºmenes existentes ---\n",
    "existing = {f for f in os.listdir(ROIS_SUBDIR) if f.endswith(\".nii.gz\")}\n",
    "to_process = [vid for vid in loaded_data.keys() if f\"{vid}.nii.gz\" not in existing]\n",
    "print(f\"ðŸ”„ Procesando {len(to_process)} volÃºmenes con pipeline de roi.ipynb (bÃºsqueda multi-eje)...\")\n",
    "\n",
    "# --- Procesamiento masivo ---\n",
    "for vol_id in tqdm(to_process, desc=\"Generando ROIs\"):\n",
    "    try:\n",
    "        # --- Cargar volumen ---\n",
    "        data = loaded_data[vol_id]\n",
    "        vol_orig = nib.load(data[\"img_path\"]).get_fdata(dtype=np.float32)\n",
    "        affine = data[\"affine\"]\n",
    "        header = data[\"header\"]\n",
    "        vol_clip = np.clip(vol_orig, HU_MIN, HU_MAX)\n",
    "        Z, Y, X = vol_clip.shape\n",
    "\n",
    "        # --- Paso 1: Semillas con bÃºsqueda multi-eje (Â¡MISMA LÃ“GICA que Cell 2-3!) ---\n",
    "        seeds = (vol_clip <= AIR_THR_STRICT_ROI)\n",
    "        seeds = clear_border(seeds)\n",
    "        seeds = remove_small_objects(seeds, min_size=MIN_SIZE_ROI)\n",
    "\n",
    "        # Regiones de bÃºsqueda para cada eje\n",
    "        delta_z = Z // 10\n",
    "        delta_y = Y // 8\n",
    "        delta_x = X // 8\n",
    "\n",
    "        # Axial: alrededor de Z//2\n",
    "        axial_region = np.zeros_like(seeds, dtype=bool)\n",
    "        z_axial = Z // 2\n",
    "        axial_region[max(0, z_axial - delta_z):min(Z, z_axial + delta_z), :, :] = True\n",
    "\n",
    "        # Coronal: alrededor de Y//2\n",
    "        coronal_region = np.zeros_like(seeds, dtype=bool)\n",
    "        y_coronal = Y // 2\n",
    "        coronal_region[:, max(0, y_coronal - delta_y):min(Y, y_coronal + delta_y), :] = True\n",
    "\n",
    "        # Sagittal: alrededor de X//2\n",
    "        sagittal_region = np.zeros_like(seeds, dtype=bool)\n",
    "        x_sagittal = X // 2\n",
    "        sagittal_region[:, :, max(0, x_sagittal - delta_x):min(X, x_sagittal + delta_x)] = True\n",
    "\n",
    "        # IntersecciÃ³n de regiones\n",
    "        search_region = axial_region & coronal_region & sagittal_region\n",
    "        trachea_cand = seeds & search_region\n",
    "\n",
    "        # DetecciÃ³n de trÃ¡quea\n",
    "        trachea = np.zeros_like(seeds, dtype=bool)\n",
    "        labeled_top, n_top = cc_label(trachea_cand)\n",
    "        if n_top > 0:\n",
    "            sizes = np.bincount(labeled_top.ravel())\n",
    "            sizes[0] = 0\n",
    "            main_label = np.argmax(sizes)\n",
    "            trachea = (labeled_top == main_label)\n",
    "\n",
    "        # --- Paso 2: BFS optimizado (6-conectado) ---\n",
    "        airways_mask = np.zeros_like(seeds, dtype=np.uint8)\n",
    "        seed_pts = np.argwhere(trachea)\n",
    "\n",
    "        if len(seed_pts) > 0:\n",
    "            q = deque(seed_pts[:100])  # Limitar semillas iniciales\n",
    "            for pt in seed_pts[:100]:\n",
    "                airways_mask[tuple(pt)] = 1\n",
    "\n",
    "            neighbors = [(1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)]\n",
    "            while q:\n",
    "                z, y, x = q.popleft()\n",
    "                for dz, dy, dx in neighbors:\n",
    "                    nz, ny, nx = z + dz, y + dy, x + dx\n",
    "                    if (0 <= nz < Z and 0 <= ny < Y and 0 <= nx < X and \n",
    "                        airways_mask[nz, ny, nx] == 0 and vol_clip[nz, ny, nx] <= GROW_THR_ROI):\n",
    "                        airways_mask[nz, ny, nx] = 1\n",
    "                        q.append((nz, ny, nx))\n",
    "\n",
    "        # --- Paso 3: Componente conectada ---\n",
    "        labeled_airways, n_airways = cc_label(airways_mask)\n",
    "        if n_airways > 0 and len(seed_pts) > 0:\n",
    "            sz, sy, sx = seed_pts[0]\n",
    "            seed_label = labeled_airways[sz, sy, sx]\n",
    "            airways_mask = (labeled_airways == seed_label).astype(np.uint8)\n",
    "\n",
    "        # --- Paso 4: Post-procesamiento (Â¡MISMO que Cell 2-3!) ---\n",
    "        mask_clean = remove_small_objects(airways_mask.astype(bool), min_size=MIN_SIZE_ROI)\n",
    "        mask_closed = binary_closing(mask_clean, footprint=ball(SMOOTH_RADIUS_ROI))\n",
    "        mask_filled = binary_fill_holes(mask_closed)\n",
    "        mask_closed3d = binary_closing(mask_filled, footprint=ball(2))  # Usar skimage.binary_closing\n",
    "        mask_dilated = binary_dilation(mask_closed3d, footprint=ball(1))\n",
    "        final_roi = binary_fill_holes(mask_dilated).astype(np.uint8)\n",
    "\n",
    "        # --- Eliminar fondo de forma robusta ---\n",
    "        background_mask = (vol_clip <= -1000)\n",
    "        final_roi[background_mask] = 0\n",
    "\n",
    "        # --- Guardar ---\n",
    "        output_path = os.path.join(ROIS_SUBDIR, f\"{vol_id}.nii.gz\")\n",
    "        nib.save(nib.Nifti1Image(final_roi, affine, header), output_path)\n",
    "\n",
    "        # --- Limpieza de memoria ---\n",
    "        del vol_orig, vol_clip, final_roi\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error en {vol_id}: {e}\")\n",
    "        gc.collect()\n",
    "\n",
    "print(\"âœ… ROIs generadas para todos los volÃºmenes. Pipeline fiel a Cell 2-3 (bÃºsqueda multi-eje).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f2f825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Procesando 0 volÃºmenes con Cell 4 TUBULAR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cell 4 TUBULAR: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cell 4 TUBULAR aplicada a todos los volÃºmenes. MÃ©tricas en 'airways_metrics.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4: SegmentaciÃ³n masiva de vÃ­as aÃ©reas + mÃ©tricas (VersiÃ³n TUBULAR - SIN MEMORY ERROR)\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import csv\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import ball\n",
    "from scipy.ndimage import label as cc_label, binary_dilation, binary_closing\n",
    "from collections import deque\n",
    "\n",
    "# --- Rutas ---\n",
    "BASE_OUTPUT_DIR = r\".\"\n",
    "ROIS_DIR = os.path.join(BASE_OUTPUT_DIR, \"rois_auto\")\n",
    "AIRWAYS_SUBDIR = os.path.join(BASE_OUTPUT_DIR, \"airways_auto\")\n",
    "METRICS_FILE = os.path.join(BASE_OUTPUT_DIR, \"airways_metrics.csv\")\n",
    "\n",
    "os.makedirs(AIRWAYS_SUBDIR, exist_ok=True)\n",
    "\n",
    "# --- ParÃ¡metros ---\n",
    "HU_MIN, HU_MAX = -1024, 600\n",
    "\n",
    "# --- FunciÃ³n de carga eficiente ---\n",
    "def load_volume_efficient(nii_path, dtype=np.float32):\n",
    "    \"\"\"Carga volumen sin mantener todo en memoria innecesariamente.\"\"\"\n",
    "    img = nib.load(nii_path)\n",
    "    # Acceder directamente al dataobj evita copias innecesarias\n",
    "    vol = np.asarray(img.dataobj, dtype=dtype)\n",
    "    return vol, img.affine, img.header\n",
    "\n",
    "def load_label_efficient(nii_path):\n",
    "    \"\"\"Carga label como uint8 para ahorrar memoria.\"\"\"\n",
    "    img = nib.load(nii_path)\n",
    "    label = np.asarray(img.dataobj, dtype=np.uint8)\n",
    "    return label\n",
    "\n",
    "# --- FunciÃ³n de segmentaciÃ³n TUBULAR optimizada ---\n",
    "def segment_airways_tubular(vol_clip, final_roi):\n",
    "    \"\"\"Segmenta vÃ­as aÃ©reas usando la lÃ³gica TUBULAR robusta.\"\"\"\n",
    "    Z, Y, X = vol_clip.shape\n",
    "    \n",
    "    roi_mask = (final_roi > 0)\n",
    "    if not np.any(roi_mask):\n",
    "        return np.zeros_like(vol_clip, dtype=np.uint8), 0\n",
    "    \n",
    "    roi_hu_values = vol_clip[roi_mask]\n",
    "    if len(roi_hu_values) == 0:\n",
    "        return np.zeros_like(vol_clip, dtype=np.uint8), 0\n",
    "\n",
    "    GROW_THR = np.percentile(roi_hu_values, 3)\n",
    "    AIR_THR_STRICT = min(-980, np.percentile(roi_hu_values, 0.5))\n",
    "\n",
    "    # --- BÃºsqueda multi-eje para trÃ¡quea ---\n",
    "    seeds = (vol_clip <= AIR_THR_STRICT) & roi_mask\n",
    "\n",
    "    delta_z = Z // 10\n",
    "    delta_y = Y // 8  \n",
    "    delta_x = X // 8\n",
    "\n",
    "    axial_region = np.zeros_like(seeds, dtype=bool)\n",
    "    axial_region[max(0, Z//2 - delta_z):min(Z, Z//2 + delta_z), :, :] = True\n",
    "\n",
    "    coronal_region = np.zeros_like(seeds, dtype=bool)\n",
    "    coronal_region[:, max(0, Y//2 - delta_y):min(Y, Y//2 + delta_y), :] = True\n",
    "\n",
    "    sagittal_region = np.zeros_like(seeds, dtype=bool)\n",
    "    sagittal_region[:, :, max(0, X//2 - delta_x):min(X, X//2 + delta_x)] = True\n",
    "\n",
    "    search_region = axial_region & coronal_region & sagittal_region\n",
    "    trachea_candidates = seeds & search_region\n",
    "\n",
    "    labeled_trachea, num_components = cc_label(trachea_candidates)\n",
    "    if num_components == 0:\n",
    "        return np.zeros_like(vol_clip, dtype=np.uint8), 0\n",
    "\n",
    "    component_sizes = np.bincount(labeled_trachea.ravel())\n",
    "    component_sizes[0] = 0\n",
    "    if np.all(component_sizes == 0):\n",
    "        return np.zeros_like(vol_clip, dtype=np.uint8), 0\n",
    "\n",
    "    main_trachea_label = np.argmax(component_sizes)\n",
    "    trachea = (labeled_trachea == main_trachea_label)\n",
    "    seed_points = np.argwhere(trachea)\n",
    "\n",
    "    if len(seed_points) == 0:\n",
    "        return np.zeros_like(vol_clip, dtype=np.uint8), 0\n",
    "\n",
    "    # --- BFS estricto ---\n",
    "    airways_bfs = np.zeros_like(seeds, dtype=np.uint8)\n",
    "    queue = deque(seed_points[:200])  # Limitar semillas iniciales\n",
    "    \n",
    "    for pt in seed_points[:200]:\n",
    "        airways_bfs[tuple(pt)] = 1\n",
    "\n",
    "    def get_neighbors(z, y, x, shape):\n",
    "        for dz, dy, dx in [(1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)]:\n",
    "            nz, ny, nx = z + dz, y + dy, x + dx\n",
    "            if 0 <= nz < shape[0] and 0 <= ny < shape[1] and 0 <= nx < shape[2]:\n",
    "                yield nz, ny, nx\n",
    "\n",
    "    while queue:\n",
    "        z, y, x = queue.popleft()\n",
    "        for nz, ny, nx in get_neighbors(z, y, x, airways_bfs.shape):\n",
    "            if (airways_bfs[nz, ny, nx] == 0 and \n",
    "                final_roi[nz, ny, nx] > 0 and \n",
    "                vol_clip[nz, ny, nx] <= GROW_THR):\n",
    "                airways_bfs[nz, ny, nx] = 1\n",
    "                queue.append((nz, ny, nx))\n",
    "\n",
    "    # Post-procesamiento\n",
    "    airways_mask = airways_bfs.astype(bool)\n",
    "    airways_mask = binary_dilation(airways_mask, iterations=1)\n",
    "    airways_mask = binary_closing(airways_mask, structure=ball(2))\n",
    "\n",
    "    # --- Filtrado tubular ---\n",
    "    labeled_mask, n_comp = cc_label(airways_mask)\n",
    "    if n_comp == 0:\n",
    "        return airways_mask.astype(np.uint8), len(seed_points)\n",
    "    \n",
    "    comp_sizes = np.bincount(labeled_mask.ravel())\n",
    "    comp_sizes[0] = 0\n",
    "    if len(comp_sizes) <= 1 or np.all(comp_sizes == 0):\n",
    "        return airways_mask.astype(np.uint8), len(seed_points)\n",
    "    \n",
    "    main_comp_id = np.argmax(comp_sizes)\n",
    "    valid_mask = (labeled_mask == main_comp_id)\n",
    "    \n",
    "    if n_comp > 1:\n",
    "        for i in range(1, n_comp + 1):\n",
    "            if i == main_comp_id:\n",
    "                continue\n",
    "            comp = (labeled_mask == i)\n",
    "            size = np.sum(comp)\n",
    "            if size < 30 or size > 50000:\n",
    "                continue\n",
    "            coords = np.argwhere(comp)\n",
    "            if coords.size == 0:\n",
    "                continue\n",
    "            try:\n",
    "                z_min, y_min, x_min = coords.min(axis=0)\n",
    "                z_max, y_max, x_max = coords.max(axis=0)\n",
    "                dims = np.sort([max(1, z_max-z_min), max(1, y_max-y_min), max(1, x_max-x_min)])\n",
    "                if dims[2] >= 2 * dims[0]:\n",
    "                    valid_mask = valid_mask | comp\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    airways_mask = valid_mask\n",
    "\n",
    "    # --- ExtensiÃ³n iterativa ---\n",
    "    extended = airways_mask.copy()\n",
    "    frontier_current = airways_mask.copy()\n",
    "    thresholds = [-890, -400, 0]\n",
    "    for thr in thresholds:\n",
    "        next_frontier = np.zeros_like(extended)\n",
    "        dilated = binary_dilation(frontier_current, iterations=1)\n",
    "        frontier = dilated & (~extended)\n",
    "        for z, y, x in np.argwhere(frontier):\n",
    "            if final_roi[z, y, x] > 0 and vol_clip[z, y, x] <= thr:\n",
    "                extended[z, y, x] = 1\n",
    "                next_frontier[z, y, x] = 1\n",
    "        frontier_current = next_frontier\n",
    "        if not np.any(frontier_current):\n",
    "            break\n",
    "\n",
    "    return extended.astype(np.uint8), len(seed_points)\n",
    "\n",
    "# --- FunciÃ³n Dice optimizada ---\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_sum = int(np.sum(y_true))\n",
    "    y_pred_sum = int(np.sum(y_pred))\n",
    "    if y_true_sum + y_pred_sum == 0:\n",
    "        return 1.0\n",
    "    intersection = int(np.sum(y_true[y_pred == 1]))\n",
    "    return (2. * intersection) / (y_true_sum + y_pred_sum)\n",
    "\n",
    "# --- Procesamiento con gestiÃ³n de memoria agresiva ---\n",
    "existing = {f for f in os.listdir(AIRWAYS_SUBDIR) if f.endswith(\".nii.gz\")}\n",
    "to_process = [vid for vid in loaded_data.keys() if f\"{vid}.nii.gz\" not in existing]\n",
    "print(f\"ðŸ”„ Procesando {len(to_process)} volÃºmenes con Cell 4 TUBULAR...\")\n",
    "\n",
    "# --- CSV setup ---\n",
    "header = [\"volume_id\", \"dice\", \"time_seconds\", \"voxels\", \"components\"]\n",
    "write_header = not os.path.exists(METRICS_FILE)\n",
    "if write_header:\n",
    "    with open(METRICS_FILE, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "\n",
    "# --- Bucle principal con gestiÃ³n de memoria ---\n",
    "for vol_id in tqdm(to_process, desc=\"Cell 4 TUBULAR\"):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Cargar datos de forma eficiente\n",
    "        data = loaded_data[vol_id]\n",
    "        vol_orig, affine, header_nib = load_volume_efficient(data[\"img_path\"])\n",
    "        label_manual = load_label_efficient(data[\"lbl_path\"])\n",
    "        vol_clip = np.clip(vol_orig, HU_MIN, HU_MAX)\n",
    "\n",
    "        # Cargar ROI\n",
    "        roi_path = os.path.join(ROIS_DIR, f\"{vol_id}.nii.gz\")\n",
    "        if not os.path.exists(roi_path):\n",
    "            print(f\"\\nâš ï¸  ROI no encontrada para {vol_id}. Saltando...\")\n",
    "            continue\n",
    "        final_roi = load_label_efficient(roi_path)\n",
    "\n",
    "        # Segmentar\n",
    "        airways_mask, n_seeds = segment_airways_tubular(vol_clip, final_roi)\n",
    "\n",
    "        # MÃ©tricas\n",
    "        dice = dice_coefficient(label_manual, airways_mask)\n",
    "        voxels = int(airways_mask.sum())\n",
    "        components = cc_label(airways_mask)[1]\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        # Guardar resultado\n",
    "        output_path = os.path.join(AIRWAYS_SUBDIR, f\"{vol_id}.nii.gz\")\n",
    "        nib.save(nib.Nifti1Image(airways_mask, affine, header_nib), output_path)\n",
    "\n",
    "        # Registrar mÃ©tricas\n",
    "        with open(METRICS_FILE, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([vol_id, f\"{dice:.4f}\", f\"{processing_time:.2f}\", voxels, components])\n",
    "\n",
    "        # LIMPIEZA AGRESIVA DE MEMORIA\n",
    "        del vol_orig, vol_clip, label_manual, final_roi, airways_mask, data\n",
    "        gc.collect()\n",
    "        \n",
    "        # Forzar liberaciÃ³n de memoria (opcional, para sistemas con poca RAM)\n",
    "        if hasattr(gc, 'collect_generations'):\n",
    "            gc.collect_generations()\n",
    "        else:\n",
    "            gc.collect()\n",
    "\n",
    "    except MemoryError:\n",
    "        print(f\"\\nMemoryWarning Memoria insuficiente para {vol_id}. Saltando...\")\n",
    "        gc.collect()\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error en {vol_id}: {e}\")\n",
    "        gc.collect()\n",
    "        continue\n",
    "\n",
    "print(\"âœ… Cell 4 TUBULAR aplicada a todos los volÃºmenes. MÃ©tricas en 'airways_metrics.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e97bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÃ©tricas cargadas: 350 casos\n",
      "\n",
      "EstadÃ­sticas generales:\n",
      "- Dice promedio: 0.5921 Â± 0.2841\n",
      "- VÃ³xeles promedio: 124,313 Â± 69,022\n",
      "- Rango Dice: [0.0000, 0.8931]\n",
      "\n",
      "Casos de alta calidad (Dice > 0.75): 115\n",
      "- Dice promedio (alta calidad): 0.7928\n",
      "- VÃ³xeles promedio (alta calidad): 165,846\n",
      "\n",
      "VerificaciÃ³n de emparejamiento:\n",
      "- Casos automÃ¡ticos: 150\n",
      "- Casos manuales: 150\n",
      "- Casos emparejados: 150\n",
      "\n",
      "Casos vÃ¡lidos de alta calidad para entrenamiento: 115\n",
      "\n",
      "PreparaciÃ³n completada. Lista guardada en: ./high_quality_cases.txt\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Celda de EvaluaciÃ³n: ValidaciÃ³n de Labels AutomÃ¡ticos (Full ROI)\n",
    "# Verifica la calidad de los labels generados por el pipeline tubular\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Rutas\n",
    "METRICS_FILE = \"./airways_metrics.csv\"\n",
    "AIRWAYS_AUTO_DIR = \"./airways_auto\"\n",
    "MANUAL_LABELS_DIR = \"./TrainBatch1/labelsTr\"\n",
    "\n",
    "# ValidaciÃ³n de archivo de mÃ©tricas\n",
    "if not os.path.exists(METRICS_FILE):\n",
    "    raise FileNotFoundError(f\"Archivo de mÃ©tricas no encontrado: {METRICS_FILE}\")\n",
    "\n",
    "# Carga de mÃ©tricas\n",
    "metrics_df = pd.read_csv(METRICS_FILE)\n",
    "print(f\"MÃ©tricas cargadas: {len(metrics_df)} casos\")\n",
    "\n",
    "# EstadÃ­sticas descriptivas\n",
    "dice_mean = metrics_df['dice'].mean()\n",
    "dice_std = metrics_df['dice'].std()\n",
    "voxels_mean = metrics_df['voxels'].mean()\n",
    "voxels_std = metrics_df['voxels'].std()\n",
    "\n",
    "print(f\"\\nEstadÃ­sticas generales:\")\n",
    "print(f\"- Dice promedio: {dice_mean:.4f} Â± {dice_std:.4f}\")\n",
    "print(f\"- VÃ³xeles promedio: {voxels_mean:,.0f} Â± {voxels_std:,.0f}\")\n",
    "print(f\"- Rango Dice: [{metrics_df['dice'].min():.4f}, {metrics_df['dice'].max():.4f}]\")\n",
    "\n",
    "# Filtrado por calidad\n",
    "HIGH_QUALITY_THRESHOLD = 0.75\n",
    "high_quality_df = metrics_df[metrics_df[\"dice\"] > HIGH_QUALITY_THRESHOLD]\n",
    "print(f\"\\nCasos de alta calidad (Dice > {HIGH_QUALITY_THRESHOLD}): {len(high_quality_df)}\")\n",
    "print(f\"- Dice promedio (alta calidad): {high_quality_df['dice'].mean():.4f}\")\n",
    "print(f\"- VÃ³xeles promedio (alta calidad): {high_quality_df['voxels'].mean():,.0f}\")\n",
    "\n",
    "# VerificaciÃ³n de emparejamiento\n",
    "def extract_case_id(filename):\n",
    "    \"\"\"Extrae case_id de diferentes formatos.\"\"\"\n",
    "    name = filename.replace(\".nii.gz\", \"\")\n",
    "    if \"_0000\" in name:\n",
    "        return name.replace(\"_0000\", \"\")\n",
    "    return name\n",
    "\n",
    "auto_ids = set(extract_case_id(f) for f in os.listdir(AIRWAYS_AUTO_DIR) if f.endswith(\".nii.gz\"))\n",
    "manual_ids = set(extract_case_id(f) for f in os.listdir(MANUAL_LABELS_DIR) if f.endswith(\".nii.gz\"))\n",
    "common_ids = auto_ids & manual_ids\n",
    "\n",
    "print(f\"\\nVerificaciÃ³n de emparejamiento:\")\n",
    "print(f\"- Casos automÃ¡ticos: {len(auto_ids)}\")\n",
    "print(f\"- Casos manuales: {len(manual_ids)}\")\n",
    "print(f\"- Casos emparejados: {len(common_ids)}\")\n",
    "\n",
    "# ValidaciÃ³n final\n",
    "valid_high_quality = high_quality_df[high_quality_df[\"volume_id\"].isin(common_ids)]\n",
    "print(f\"\\nCasos vÃ¡lidos de alta calidad para entrenamiento: {len(valid_high_quality)}\")\n",
    "\n",
    "# Guardado de lista\n",
    "HIGH_QUALITY_CASES_FILE = \"./high_quality_cases.txt\"\n",
    "with open(HIGH_QUALITY_CASES_FILE, 'w') as f:\n",
    "    for case_id in sorted(valid_high_quality[\"volume_id\"]):\n",
    "        f.write(f\"{case_id}\\n\")\n",
    "\n",
    "# Variables globales para Cell 1\n",
    "high_quality_case_set = set(valid_high_quality[\"volume_id\"])\n",
    "print(f\"\\nPreparaciÃ³n completada. Lista guardada en: {HIGH_QUALITY_CASES_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
